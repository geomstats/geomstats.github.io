
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hyperbolic Embedding of Graphs and Clustering &#8212; Geomstats latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space';</script>
    <link rel="canonical" href="geomstats.github.io/notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classifying hands poses with Kendall shape spaces" href="14_real_world_applications__hand_poses_analysis_in_kendall_shape_space.html" />
    <link rel="prev" title="Hand gesture classification with EMG data using Riemannian metrics" href="12_real_world_applications__emg_sign_classification_in_spd_manifold.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Apr 8, 2024, 10:19:45 AM"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Geomstats latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../explanation/index.html">
                        Explanation
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../contributing/index.html">
                        Contributing Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/index.html">
                        API Reference
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
                        Roadmap
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../governance.html">
                        Governance
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../gsod.html">
                        Google Season of Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../hackathons.html">
                        Hackathons
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../explanation/index.html">
                        Explanation
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../contributing/index.html">
                        Contributing Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/index.html">
                        API Reference
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links-2">
                    More
                </button>
                <ul id="pst-nav-more-links-2" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
                        Roadmap
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../governance.html">
                        Governance
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../gsod.html">
                        Google Season of Docs
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../hackathons.html">
                        Hackathons
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="03_practical_methods__data_on_manifolds.html">Data on Manifolds</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_practical_methods__from_vector_spaces_to_manifolds.html">From vector spaces to manifolds</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_practical_methods__simple_machine_learning_on_tangent_spaces.html">Learning on Tangent Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_practical_methods__riemannian_frechet_mean_and_tangent_pca.html">Fréchet Mean and Tangent PCA</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_practical_methods__riemannian_kmeans.html">K-Means clustering on a Riemannian Manifold</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_practical_methods__information_geometry.html">Information geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_practical_methods__implement_your_own_riemannian_geometry.html">Implement your own Riemannian Geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_practical_methods__shape_analysis.html">Shape analysis of curves with the Square Root Velocity metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="19_practical_methods__aac.html">Align all and Compute for Graphs</a></li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="11_real_world_applications__cell_shapes_analysis.html">Shape Analysis of Cancer Cells</a></li>









<li class="toctree-l1"><a class="reference internal" href="12_real_world_applications__emg_sign_classification_in_spd_manifold.html">Hand gesture classification with EMG data using Riemannian metrics</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Hyperbolic Embedding of Graphs and Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_real_world_applications__hand_poses_analysis_in_kendall_shape_space.html">Classifying hands poses with Kendall shape spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_real_world_applications__optic_nerve_heads_analysis_in_kendall_shape_space.html">Computing with shapes of landmarks in Kendall shape spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_real_world_applications__visualizations_in_kendall_shape_spaces.html">Computing with triangular shapes in Kendall framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_real_world_applications__sao_paulo_traffic_optimization.html">Optimization of Sao Paulo traffic</a></li>






<li class="toctree-l1"><a class="reference internal" href="20_real_world_applications__graph_space.html">Graph Space</a></li>


</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Hyperbolic...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="admonition note">
  <p>Notebook source code:
    <a class="reference external" href="https://github.com/geomstats/geomstats/blob/main/notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space.ipynb">notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space.ipynb</a>
    <br>Run it yourself on binder
    <a href="https://mybinder.org/v2/gh/geomstats/geomstats/main?filepath=notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space.ipynb"><img alt="Binder badge"
    src="https://mybinder.org/badge_logo.svg"
    style="vertical-align:text-bottom"></a>
  </p>
</div><section id="Hyperbolic-Embedding-of-Graphs-and-Clustering">
<h1>Hyperbolic Embedding of Graphs and Clustering<a class="headerlink" href="#Hyperbolic-Embedding-of-Graphs-and-Clustering" title="Link to this heading">#</a></h1>
<p>Lead authors: Thomas Gerald and Hadi Zaatiti.</p>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading">#</a></h2>
<p>From social networks to parse trees, knowledge graphs to protein interaction networks, Graph-Structured Data is endemic to a wide variety of natural and engineered systems. Often, understanding the structure and/or dynamics of these graphs yields insight into the systems under investigation. Take, for example, the problems of finding key influencers or distinct communities within social networks.</p>
<p>The goal of graph embedding is to find a way of representing the graph in a space which more readily lends itself to analysis/investigation. One approach is to identify points in a vector space with nodes of the graph in such a way that important relations between nodes are preserved via relations between their corresponding points.</p>
<p>There are a wide variety of methods which approach this problem in different ways and for different aims, say for clustering or for link prediction. Recently, the embedding of Graph Structured Data (GSD) on manifolds has received considerable attention. In particular, much work has shown that hyperbolic spaces are beneficial for a wide variety of tasks with GSD <a class="reference internal" href="#References"><span class="std std-ref">[ND2017]</span></a>. This tutorial shows how to learn such embeddings using the Poincaré Ball manifold and the well-known ‘Karate
Club’ social network dataset with <code class="docutils literal notranslate"><span class="pre">geomstats</span></code>. This data and several others can be found in the <code class="docutils literal notranslate"><span class="pre">datasets.data</span></code> module of the project’s github repository.</p>
<p><img alt="KarateEmbedding" src="../_images/karate_embedding_iterations.gif" /> <em>Learning a Poincaré disk embedding of the Karate club graph dataset</em></p>
<p>We start by importing standard tools for logging and visualization, allowing us to draw the embedding of the GSD on the manifold. Next, we import the manifold of interest, visualization tools, and other methods from <code class="docutils literal notranslate"><span class="pre">geomstats</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">geomstats.backend</span> <span class="k">as</span> <span class="nn">gs</span>
<span class="kn">import</span> <span class="nn">geomstats.visualization</span> <span class="k">as</span> <span class="nn">visualization</span>

<span class="kn">from</span> <span class="nn">geomstats.datasets.utils</span> <span class="kn">import</span> <span class="n">load_karate_graph</span>
<span class="kn">from</span> <span class="nn">geomstats.geometry.poincare_ball</span> <span class="kn">import</span> <span class="n">PoincareBall</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO: Using numpy backend
</pre></div></div>
</div>
</section>
<section id="Parameters-and-Initialization">
<h2>Parameters and Initialization<a class="headerlink" href="#Parameters-and-Initialization" title="Link to this heading">#</a></h2>
<p>We define the following parameters needed for embedding:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>random.seed</p></td>
<td><p>An initial manually set number for generating pseudorandom numbers</p></td>
</tr>
<tr class="row-odd"><td><p>dim</p></td>
<td><p>Dimensions of the manifold used for embedding</p></td>
</tr>
<tr class="row-even"><td><p>max_epochs</p></td>
<td><p>Number of iterations for learning the embedding</p></td>
</tr>
<tr class="row-odd"><td><p>lr</p></td>
<td><p>Learning rate</p></td>
</tr>
<tr class="row-even"><td><p>n_negative</p></td>
<td><p>Number of negative samples</p></td>
</tr>
<tr class="row-odd"><td><p>context_size</p></td>
<td><p>Size of the considered context for each node of the graph</p></td>
</tr>
</tbody>
</table>
<p>Let us discuss a few things about the parameters of the above table. The number of dimensions should be high (i.e., 10+) for large datasets (i.e., where the number of nodes/edges is significantly large). In this tutorial we consider a dataset that is quite small with only 34 nodes. The Poincaré disk of only two dimensions is therefore sufficient to capture the complexity of the graph and provide a faithful representation. Some parameters are hard to know in advance, such as <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> and
<code class="docutils literal notranslate"><span class="pre">lr</span></code>. These should be tuned specifically for each dataset. Visualization can help with tuning the parameters. Also, one can perform a grid search to find values of these parameters which maximize some performance function. In learning embeddings, one can consider performance metrics such as a measure for cluster seperability or normalized mutual information (NMI) or others. Similarly, the number of negative samples and context size can also be thought of as hyperparameters and will be further
discussed in the sequel. An instance of the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> class is created and set to the Karate club dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">n_negative</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">context_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">karate_graph</span> <span class="o">=</span> <span class="n">load_karate_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The Zachary karate club network was collected from the members of a university karate club by Wayne Zachary in 1977. Each node represents a member of the club, and each edge represents an undirected relation between two members. An often discussed problem using this dataset is to find the two groups of people into which the karate club split after an argument between two teachers. <img alt="d131d5fec55a46c9abb899eafa78e98e" class="no-scaled-link" src="../_images/karate_graph.png" style="width: 60%;" /> Some information about the dataset is displayed to provide insight into its
complexity.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nb_vertices_by_edges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">e_2</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">e_2</span> <span class="ow">in</span> <span class="n">karate_graph</span><span class="o">.</span><span class="n">edges</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Number of vertices: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">karate_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">))</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
    <span class="s2">&quot;Mean edge-vertex ratio: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">nb_vertices_by_edges</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">karate_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO: Number of vertices: 34
INFO: Mean edge-vertex ratio: 4.588235294117647
</pre></div></div>
</div>
<p>Denote <span class="math notranslate nohighlight">\(V\)</span> as the set of nodes and <span class="math notranslate nohighlight">\(E \subset V\times V\)</span> the set of edges. The goal of embedding GSD is to provide a faithful and exploitable representation of the graph structure. It is mainly achieved by preserving <em>first-order</em> proximity that enforces nodes sharing edges to be close to each other. It can additionally preserve <em>second-order</em> proximity that enforces two nodes sharing the same context (i.e., nodes that share neighbors but are not necessarily directly connected) to be
close. Let <span class="math notranslate nohighlight">\(\mathbb{B}^m\)</span> be the Poincaré Ball of dimension <span class="math notranslate nohighlight">\(m\)</span> equipped with the distance function <span class="math notranslate nohighlight">\(d\)</span>. The below figure shows geodesics between pairs of points on <span class="math notranslate nohighlight">\(\mathbb{B}^2\)</span>. Geodesics are the shortest path between two points. The distance function <span class="math notranslate nohighlight">\(d\)</span> of two points is the length of the geodesic that links them.</p>
<p><img alt="4e5f4245526a47bbb43b3bf3258b0170" class="no-scaled-link" src="../_images/geodesics.png" style="width: 40%;" /></p>
<p>Declaring an instance of the <code class="docutils literal notranslate"><span class="pre">PoincareBall</span></code> manifold of two dimensions in <code class="docutils literal notranslate"><span class="pre">geomstats</span></code> is straightforward:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hyperbolic_manifold</span> <span class="o">=</span> <span class="n">PoincareBall</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><em>first</em> and <em>second-order</em> proximities can be achieved by optimising the following loss functions:</p>
</section>
<section id="Loss-function.">
<h2>Loss function.<a class="headerlink" href="#Loss-function." title="Link to this heading">#</a></h2>
<p>To preserve first and second-order proximities we adopt a loss function similar to (Nickel, 2017) and consider the negative sampling approach as in (Mikolov, 2013) :</p>
<div class="math notranslate nohighlight">
\[\mathcal{L} = - \sum_{v_i\in V} \sum_{v_j \in C_i} \bigg[ log(\sigma(-d^2(\phi_i, \phi_j'))) + \sum_{v_k\sim \mathcal{P}_n} log(\sigma(d^2(\phi_i, \phi_k')))  \bigg]\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span> is the sigmoid function and <span class="math notranslate nohighlight">\(\phi_i \in \mathbb{B}^m\)</span> is the embedding of the <span class="math notranslate nohighlight">\(i\)</span>-th node of <span class="math notranslate nohighlight">\(V\)</span>, <span class="math notranslate nohighlight">\(C_i\)</span> the nodes in the context of the <span class="math notranslate nohighlight">\(i\)</span>-th node, <span class="math notranslate nohighlight">\(\phi_j'\in \mathbb{B}^m\)</span> the embedding of <span class="math notranslate nohighlight">\(v_j\in C_i\)</span> and <span class="math notranslate nohighlight">\(\mathcal{P}_n\)</span> the negative sampling distribution over <span class="math notranslate nohighlight">\(V\)</span>: <span class="math notranslate nohighlight">\(\mathcal{P}_n(v)=\frac{deg(v)^{3/4}}{\sum_{v_i\in V}deg(v_i)^{3/4}}\)</span>. Intuitively one can see that to minimizing <span class="math notranslate nohighlight">\(L\)</span>,
the distance between <span class="math notranslate nohighlight">\(v_i\)</span> and <span class="math notranslate nohighlight">\(v_j\)</span> should get smaller, while the one between <span class="math notranslate nohighlight">\(v_i\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span> would get larger. <img alt="44a503cb4ed34c6ea728080d59487efe" class="no-scaled-link" src="../_images/notations.png" style="width: 40%;" /></p>
</section>
<section id="Riemannian-optimization.">
<h2>Riemannian optimization.<a class="headerlink" href="#Riemannian-optimization." title="Link to this heading">#</a></h2>
<p>Following the idea of (Ganea, 2018) we use the following formula to optimize <span class="math notranslate nohighlight">\(L\)</span>:</p>
<div class="math notranslate nohighlight">
\[\phi^{t+1} = \text{Exp}_{\phi^t} \left( -lr \frac{\partial L}{\partial \phi} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi\)</span> is a parameter of <span class="math notranslate nohighlight">\(L\)</span>, <span class="math notranslate nohighlight">\(t\in\{1,2,\cdots\}\)</span> is the epoch iteration number and <span class="math notranslate nohighlight">\(lr\)</span> is the learning rate. The formula consists of first computing the usual gradient of the loss function giving the direction in which the parameter should move. The Riemannian exponential map <span class="math notranslate nohighlight">\(\text{Exp}\)</span> is a function that takes a base point <span class="math notranslate nohighlight">\(\phi^t\)</span> and some direction vector <span class="math notranslate nohighlight">\(T\)</span> and returns the point <span class="math notranslate nohighlight">\(\phi^{t+1}\)</span> such that <span class="math notranslate nohighlight">\(\phi^{t+1}\)</span> belongs to
the geodesic initiated from <span class="math notranslate nohighlight">\(\phi{t}\)</span> in the direction of <span class="math notranslate nohighlight">\(T\)</span> and the length of the geoedesic curve between <span class="math notranslate nohighlight">\(\phi^t\)</span> and <span class="math notranslate nohighlight">\(\phi^{t+1}\)</span> is of 1 unit. The Riemannian exponential map is implemented as a method of the <code class="docutils literal notranslate"><span class="pre">PoincareBallMetric</span></code> class in the <code class="docutils literal notranslate"><span class="pre">geometry</span></code> module of <code class="docutils literal notranslate"><span class="pre">geomstats</span></code>.</p>
<p>Therefore to minimize <span class="math notranslate nohighlight">\(L\)</span> we will need to compute its gradient. Several steps are required to do so, 1. Compute the gradient of the squared distance 2. Compute the gradient of the log sigmoid 3. Compute the gradient of the composision of 1. and 2.</p>
<p>For 1., we use the formula proposed by (Arnaudon, 2013) which uses the Riemannian logarithmic map to compute the gradient of the distance. This is implemented as</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">grad_squared_distance</span><span class="p">(</span><span class="n">point_a</span><span class="p">,</span> <span class="n">point_b</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gradient of squared hyperbolic distance.</span>

<span class="sd">    Gradient of the squared distance based on the</span>
<span class="sd">    Ball representation according to point_a</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    point_a : array-like, shape=[n_samples, dim]</span>
<span class="sd">        First point in hyperbolic space.</span>
<span class="sd">    point_b : array-like, shape=[n_samples, dim]</span>
<span class="sd">        Second point in hyperbolic space.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dist : array-like, shape=[n_samples, 1]</span>
<span class="sd">        Geodesic squared distance between the two points.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_map</span> <span class="o">=</span> <span class="n">PoincareBall</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">point_b</span><span class="p">,</span> <span class="n">point_a</span><span class="p">)</span>

    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">log_map</span>
</pre></div>
</div>
</div>
<p>For 2. define the <code class="docutils literal notranslate"><span class="pre">log_sigmoid</span></code> corresponding as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_sigmoid</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Logsigmoid function.</span>

<span class="sd">    Apply log sigmoid function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector : array-like, shape=[n_samples, dim]</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : array-like, shape=[n_samples, dim]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gs</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">gs</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">vector</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<p>The gradient of the logarithm of sigmoid function is implemented as:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">grad_log_sigmoid</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gradient of log sigmoid function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector : array-like, shape=[n_samples, dim]</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gradient : array-like, shape=[n_samples, dim]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">gs</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">vector</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>For 3., apply the composition rule to obtain the gradient of <span class="math notranslate nohighlight">\(L\)</span>. The following function given <span class="math notranslate nohighlight">\(\phi_i\)</span>, <span class="math notranslate nohighlight">\(\phi'_j\)</span> and <span class="math notranslate nohighlight">\(\phi'_k\)</span> returns the total value of <span class="math notranslate nohighlight">\(L\)</span> and its gradient vector at <span class="math notranslate nohighlight">\(\phi_i\)</span>. For the value of <span class="math notranslate nohighlight">\(L\)</span> the loss function formula is simply applied. For the gradient, we apply the composition of <code class="docutils literal notranslate"><span class="pre">grad_log_sigmoid</span></code> with <code class="docutils literal notranslate"><span class="pre">grad_squared_distance</span></code> while paying attention to the signs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">example_embedding</span><span class="p">,</span> <span class="n">context_embedding</span><span class="p">,</span> <span class="n">negative_embedding</span><span class="p">,</span> <span class="n">manifold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute loss and grad.</span>

<span class="sd">    Compute loss and grad given embedding of the current example,</span>
<span class="sd">    embedding of the context and negative sampling embedding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_edges</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">negative_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">example_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">example_embedding</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">example_embedding</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">context_embedding</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">context_embedding</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">positive_distance</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">squared_dist</span><span class="p">(</span>
        <span class="n">example_embedding</span><span class="p">,</span> <span class="n">context_embedding</span>
    <span class="p">)</span>
    <span class="n">positive_loss</span> <span class="o">=</span> <span class="n">log_sigmoid</span><span class="p">(</span><span class="o">-</span><span class="n">positive_distance</span><span class="p">)</span>

    <span class="n">reshaped_example_embedding</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">example_embedding</span><span class="p">,</span> <span class="n">n_edges</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">negative_distance</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">squared_dist</span><span class="p">(</span>
        <span class="n">reshaped_example_embedding</span><span class="p">,</span> <span class="n">negative_embedding</span>
    <span class="p">)</span>
    <span class="n">negative_loss</span> <span class="o">=</span> <span class="n">log_sigmoid</span><span class="p">(</span><span class="n">negative_distance</span><span class="p">)</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">positive_loss</span> <span class="o">+</span> <span class="n">negative_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

    <span class="n">positive_log_sigmoid_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">grad_log_sigmoid</span><span class="p">(</span><span class="o">-</span><span class="n">positive_distance</span><span class="p">)</span>

    <span class="n">positive_distance_grad</span> <span class="o">=</span> <span class="n">grad_squared_distance</span><span class="p">(</span><span class="n">example_embedding</span><span class="p">,</span> <span class="n">context_embedding</span><span class="p">)</span>

    <span class="n">positive_grad</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">gs</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">positive_log_sigmoid_grad</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">positive_distance_grad</span>
    <span class="p">)</span>

    <span class="n">negative_distance_grad</span> <span class="o">=</span> <span class="n">grad_squared_distance</span><span class="p">(</span>
        <span class="n">reshaped_example_embedding</span><span class="p">,</span> <span class="n">negative_embedding</span>
    <span class="p">)</span>

    <span class="n">negative_distance</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">(</span><span class="n">negative_distance</span><span class="p">,</span> <span class="n">to_ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">negative_log_sigmoid_grad</span> <span class="o">=</span> <span class="n">grad_log_sigmoid</span><span class="p">(</span><span class="n">negative_distance</span><span class="p">)</span>

    <span class="n">negative_grad</span> <span class="o">=</span> <span class="n">negative_log_sigmoid_grad</span> <span class="o">*</span> <span class="n">negative_distance_grad</span>
    <span class="n">example_grad</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">positive_grad</span> <span class="o">+</span> <span class="n">negative_grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">example_grad</span>
</pre></div>
</div>
</div>
</section>
<section id="Capturing-the-graph-structure">
<h2>Capturing the graph structure<a class="headerlink" href="#Capturing-the-graph-structure" title="Link to this heading">#</a></h2>
<p>At this point we have the necessary bricks to compute the resulting gradient of <span class="math notranslate nohighlight">\(L\)</span>. We are ready to prepare the nodes <span class="math notranslate nohighlight">\(v_i\)</span>, <span class="math notranslate nohighlight">\(v_j\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span> and initialise their embeddings <span class="math notranslate nohighlight">\(\phi_i\)</span>, <span class="math notranslate nohighlight">\(\phi^{'}_j\)</span> and <span class="math notranslate nohighlight">\(\phi^{'}_k\)</span>. First, initialize an array that will hold embeddings <span class="math notranslate nohighlight">\(\phi_i\)</span> of each node <span class="math notranslate nohighlight">\(v_i\in V\)</span> with random points belonging to the Poincaré disk.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">karate_graph</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">*</span> <span class="mf">0.2</span>
</pre></div>
</div>
</div>
<p>Next, to prepare the context nodes <span class="math notranslate nohighlight">\(v_j\)</span> for each node <span class="math notranslate nohighlight">\(v_i\)</span>, we compute random walks initialised from each <span class="math notranslate nohighlight">\(v_i\)</span> up to some length (5 by default). The latter is done via a special function within the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> class. The nodes <span class="math notranslate nohighlight">\(v_j\)</span> will be later picked from the random walk of <span class="math notranslate nohighlight">\(v_i\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_walks</span> <span class="o">=</span> <span class="n">karate_graph</span><span class="o">.</span><span class="n">random_walk</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Negatively sampled nodes <span class="math notranslate nohighlight">\(v_k\)</span> are chosen according to the previously defined probability distribution function <span class="math notranslate nohighlight">\(\mathcal{P}_n(v_k)\)</span> implemented as</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">negative_table_parameter</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">negative_sampling_table</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">nb_v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nb_vertices_by_edges</span><span class="p">):</span>
    <span class="n">negative_sampling_table</span> <span class="o">+=</span> <span class="p">(</span>
        <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="nb">int</span><span class="p">((</span><span class="n">nb_v</span> <span class="o">**</span> <span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="mf">4.0</span><span class="p">)))</span> <span class="o">*</span> <span class="n">negative_table_parameter</span>
    <span class="p">)</span>

<span class="n">negative_sampling_table</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">negative_sampling_table</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Numerically-optimizing-the-loss-function">
<h2>Numerically optimizing the loss function<a class="headerlink" href="#Numerically-optimizing-the-loss-function" title="Link to this heading">#</a></h2>
<p>Optimising the loss function is performed numerically over the number of epochs. At each iteration, we will compute the gradient of <span class="math notranslate nohighlight">\(L\)</span>. Then the graph nodes are moved in the direction pointed by the gradient. The movement of the nodes is performed by following geodesics in the gradient direction. The key to obtain an embedding representing accurately the dataset, is to move the nodes smoothly rather than brutal movements. This is done by tuning the learning rate, such as at each epoch all
the nodes made small movements.</p>
<p>A <em>first level</em> loop iterates over the epochs, the table <code class="docutils literal notranslate"><span class="pre">total_loss</span></code> will record the value of <span class="math notranslate nohighlight">\(L\)</span> at each iteration and help us track the minimization of <span class="math notranslate nohighlight">\(L\)</span>.</p>
<p>A <em>second level</em> nested loop iterates over each path in the previously computed random walks. Observing these walks, notice that nodes having many edges appear more often. Such nodes can be considered as important crossroads and will therefore be subject to a greater number of embedding updates. This is one of the main reasons why random walks have proven to be effective in capturing the structure of graphs. The context of each <span class="math notranslate nohighlight">\(v_i\)</span> will be the set of nodes <span class="math notranslate nohighlight">\(v_j\)</span> belonging to the
random walk from <span class="math notranslate nohighlight">\(v_i\)</span>. The <code class="docutils literal notranslate"><span class="pre">context_size</span></code> specified earlier will limit the length of the walk to be considered. Similarly, we use the same <code class="docutils literal notranslate"><span class="pre">context_size</span></code> to limit the number of negative samples. We find <span class="math notranslate nohighlight">\(\phi_i\)</span> from the <code class="docutils literal notranslate"><span class="pre">embeddings</span></code> array.</p>
<p>A <em>third level</em> nested loop will iterate on each <span class="math notranslate nohighlight">\(v_j\)</span> and <span class="math notranslate nohighlight">\(v_k\)</span>. From within, we find <span class="math notranslate nohighlight">\(\phi'_j\)</span> and <span class="math notranslate nohighlight">\(\phi'_k\)</span> then call the <code class="docutils literal notranslate"><span class="pre">loss</span></code> function to compute the gradient. Then the Riemannian exponential map is applied to find the new value of <span class="math notranslate nohighlight">\(\phi_i\)</span> as we mentioned before.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">random_walks</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">example_index</span><span class="p">,</span> <span class="n">one_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">context_index</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span>
                <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">example_index</span> <span class="o">-</span> <span class="n">context_size</span><span class="p">)</span> <span class="p">:</span> <span class="nb">min</span><span class="p">(</span>
                    <span class="n">example_index</span> <span class="o">+</span> <span class="n">context_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">]</span>
            <span class="n">negative_index</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                <span class="n">negative_sampling_table</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">context_index</span><span class="p">),</span> <span class="n">n_negative</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">negative_index</span> <span class="o">=</span> <span class="n">negative_sampling_table</span><span class="p">[</span><span class="n">negative_index</span><span class="p">]</span>

            <span class="n">example_embedding</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">one_path</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">one_context_i</span><span class="p">,</span> <span class="n">one_negative_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">context_index</span><span class="p">,</span> <span class="n">negative_index</span><span class="p">):</span>
                <span class="n">context_embedding</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">one_context_i</span><span class="p">]</span>
                <span class="n">negative_embedding</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">one_negative_i</span><span class="p">]</span>
                <span class="n">l</span><span class="p">,</span> <span class="n">g_ex</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span>
                    <span class="n">example_embedding</span><span class="p">,</span>
                    <span class="n">context_embedding</span><span class="p">,</span>
                    <span class="n">negative_embedding</span><span class="p">,</span>
                    <span class="n">hyperbolic_manifold</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">total_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>

                <span class="n">example_to_update</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">one_path</span><span class="p">]</span>
                <span class="n">embeddings</span><span class="p">[</span><span class="n">one_path</span><span class="p">]</span> <span class="o">=</span> <span class="n">hyperbolic_manifold</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
                    <span class="o">-</span><span class="n">lr</span> <span class="o">*</span> <span class="n">g_ex</span><span class="p">,</span> <span class="n">example_to_update</span>
                <span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s2">&quot;iteration </span><span class="si">%d</span><span class="s2"> loss_value </span><span class="si">%f</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">total_loss</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO: iteration 0 loss_value 1.819745
INFO: iteration 1 loss_value 1.757333
INFO: iteration 2 loss_value 1.727391
INFO: iteration 3 loss_value 1.678591
INFO: iteration 4 loss_value 1.629264
INFO: iteration 5 loss_value 1.539738
INFO: iteration 6 loss_value 1.474939
INFO: iteration 7 loss_value 1.423268
INFO: iteration 8 loss_value 1.383663
INFO: iteration 9 loss_value 1.378133
INFO: iteration 10 loss_value 1.327572
INFO: iteration 11 loss_value 1.327438
INFO: iteration 12 loss_value 1.275998
INFO: iteration 13 loss_value 1.265022
INFO: iteration 14 loss_value 1.284490
INFO: iteration 15 loss_value 1.271861
INFO: iteration 16 loss_value 1.280157
INFO: iteration 17 loss_value 1.272947
INFO: iteration 18 loss_value 1.273112
INFO: iteration 19 loss_value 1.258863
INFO: iteration 20 loss_value 1.243420
INFO: iteration 21 loss_value 1.229514
INFO: iteration 22 loss_value 1.273961
INFO: iteration 23 loss_value 1.262166
INFO: iteration 24 loss_value 1.259846
INFO: iteration 25 loss_value 1.262707
INFO: iteration 26 loss_value 1.265081
INFO: iteration 27 loss_value 1.243761
INFO: iteration 28 loss_value 1.268464
INFO: iteration 29 loss_value 1.246803
INFO: iteration 30 loss_value 1.246640
INFO: iteration 31 loss_value 1.242071
INFO: iteration 32 loss_value 1.209406
INFO: iteration 33 loss_value 1.263587
INFO: iteration 34 loss_value 1.281416
INFO: iteration 35 loss_value 1.265381
INFO: iteration 36 loss_value 1.280565
INFO: iteration 37 loss_value 1.245407
INFO: iteration 38 loss_value 1.263434
INFO: iteration 39 loss_value 1.230449
INFO: iteration 40 loss_value 1.240522
INFO: iteration 41 loss_value 1.239126
INFO: iteration 42 loss_value 1.246178
INFO: iteration 43 loss_value 1.222999
INFO: iteration 44 loss_value 1.284980
INFO: iteration 45 loss_value 1.257932
INFO: iteration 46 loss_value 1.225560
INFO: iteration 47 loss_value 1.231305
INFO: iteration 48 loss_value 1.262679
INFO: iteration 49 loss_value 1.230800
INFO: iteration 50 loss_value 1.267129
INFO: iteration 51 loss_value 1.277193
INFO: iteration 52 loss_value 1.233882
INFO: iteration 53 loss_value 1.242276
INFO: iteration 54 loss_value 1.253025
INFO: iteration 55 loss_value 1.251747
INFO: iteration 56 loss_value 1.252117
INFO: iteration 57 loss_value 1.252727
INFO: iteration 58 loss_value 1.251796
INFO: iteration 59 loss_value 1.252610
INFO: iteration 60 loss_value 1.240764
INFO: iteration 61 loss_value 1.248037
INFO: iteration 62 loss_value 1.248934
INFO: iteration 63 loss_value 1.260462
INFO: iteration 64 loss_value 1.258608
INFO: iteration 65 loss_value 1.243336
INFO: iteration 66 loss_value 1.255250
INFO: iteration 67 loss_value 1.256547
INFO: iteration 68 loss_value 1.230852
INFO: iteration 69 loss_value 1.271497
INFO: iteration 70 loss_value 1.241716
INFO: iteration 71 loss_value 1.262636
INFO: iteration 72 loss_value 1.237087
INFO: iteration 73 loss_value 1.248709
INFO: iteration 74 loss_value 1.266595
INFO: iteration 75 loss_value 1.241017
INFO: iteration 76 loss_value 1.253866
INFO: iteration 77 loss_value 1.254891
INFO: iteration 78 loss_value 1.266350
INFO: iteration 79 loss_value 1.242843
INFO: iteration 80 loss_value 1.278382
INFO: iteration 81 loss_value 1.265075
INFO: iteration 82 loss_value 1.244734
INFO: iteration 83 loss_value 1.248023
INFO: iteration 84 loss_value 1.243780
INFO: iteration 85 loss_value 1.264483
INFO: iteration 86 loss_value 1.279735
INFO: iteration 87 loss_value 1.277543
INFO: iteration 88 loss_value 1.228955
INFO: iteration 89 loss_value 1.239178
INFO: iteration 90 loss_value 1.244183
INFO: iteration 91 loss_value 1.274318
INFO: iteration 92 loss_value 1.246705
INFO: iteration 93 loss_value 1.248959
INFO: iteration 94 loss_value 1.224612
INFO: iteration 95 loss_value 1.236104
INFO: iteration 96 loss_value 1.249129
INFO: iteration 97 loss_value 1.243088
INFO: iteration 98 loss_value 1.274817
INFO: iteration 99 loss_value 1.238233
</pre></div></div>
</div>
</section>
<section id="Plotting-results">
<h2>Plotting results<a class="headerlink" href="#Plotting-results" title="Link to this heading">#</a></h2>
<p>Once the <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> iterations of epochs is achieved, we can plot the resulting <code class="docutils literal notranslate"><span class="pre">embeddings</span></code> array and the true labels shown as two colors. At 100 epochs we can see that the two group of nodes with different labels are moving away from each other on the manifold. If one increases the <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code>, then further separability is achieved.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">mpatches</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;r&quot;</span><span class="p">}</span>
<span class="n">group_1</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Group 1&quot;</span><span class="p">)</span>
<span class="n">group_2</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Group 2&quot;</span><span class="p">)</span>

<span class="n">circle</span> <span class="o">=</span> <span class="n">visualization</span><span class="o">.</span><span class="n">PoincareDisk</span><span class="p">(</span><span class="n">coords_type</span><span class="o">=</span><span class="s2">&quot;ball&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">circle</span><span class="o">.</span><span class="n">set_ax</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">circle</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i_embedding</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">pt_id</span> <span class="o">=</span> <span class="n">i_embedding</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">karate_graph</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">pt_id</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">s</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">pt_id</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Poincare Ball Embedding of the Karate Club Network&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">group_1</span><span class="p">,</span> <span class="n">group_2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space_36_0.png" src="../_images/notebooks_13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space_36_0.png" />
</div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">geomstats</span></code>, several unsupervized clustering algorithms on manifolds are implemented such as <span class="math notranslate nohighlight">\(K\)</span>-means and Expectation-Maximization.</p>
<p>Let us apply <span class="math notranslate nohighlight">\(K\)</span>-means to learn the node belonging of the two groups and see how well we predicted the true labels. Lets first import <span class="math notranslate nohighlight">\(K\)</span>-means</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">geomstats.learning.kmeans</span> <span class="kn">import</span> <span class="n">RiemannianKMeans</span>
</pre></div>
</div>
</div>
<p>Set the number of groups to 2.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
<p>Initialize an instance of <span class="math notranslate nohighlight">\(K\)</span>-means.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">RiemannianKMeans</span><span class="p">(</span>
    <span class="n">hyperbolic_manifold</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Fit the embedded nodes</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
<p>And plot the resulting labels provided by <span class="math notranslate nohighlight">\(K\)</span>-means</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">]</span>
<span class="n">circle</span> <span class="o">=</span> <span class="n">visualization</span><span class="o">.</span><span class="n">PoincareDisk</span><span class="p">(</span><span class="n">coords_type</span><span class="o">=</span><span class="s2">&quot;ball&quot;</span><span class="p">)</span>
<span class="n">fig2</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">circle</span><span class="o">.</span><span class="n">set_ax</span><span class="p">(</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">circle</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">group_1_predicted</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted Group 1&quot;</span><span class="p">)</span>
<span class="n">group_2_predicted</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted Group 2&quot;</span><span class="p">)</span>
<span class="n">group_centers</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Cluster centers&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i_embedding</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">pt_id</span> <span class="o">=</span> <span class="n">i_embedding</span>
        <span class="k">if</span> <span class="n">labels</span><span class="p">[</span><span class="n">i_embedding</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">pt_id</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i_centroid</span><span class="p">,</span> <span class="n">centroid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">centroid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">centroid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;K-means applied to Karate club embedding&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">group_1_predicted</span><span class="p">,</span> <span class="n">group_2_predicted</span><span class="p">,</span> <span class="n">group_centers</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space_46_0.png" src="../_images/notebooks_13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space_46_0.png" />
</div>
</div>
<p>By comparing the <span class="math notranslate nohighlight">\(K\)</span>-means labels and the true labels, notice how <span class="math notranslate nohighlight">\(K\)</span>-means accurately finds the two groups of nodes (not perfectly, e.g., nodes 2 and 8). We therefore achieved good performances in predicting the belonging of each member of the Karate club to one of the two groups.</p>
</section>
<section id="References">
<h2>References<a class="headerlink" href="#References" title="Link to this heading">#</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="aby2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ABY2013<span class="fn-bracket">]</span></span>
<p>Arnaudon, Marc, Frédéric Barbaresco, and Le Yang. “Riemannian medians and means with applications to radar signal processing.” IEEE Journal of Selected Topics in Signal Processing 7.4 (2013): 595-604.</p>
</div>
<div class="citation" id="gbh2018" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GBH2018<span class="fn-bracket">]</span></span>
<p>Ganea, Octavian, Gary Bécigneul, and Thomas Hofmann. “Hyperbolic neural networks.” Advances in neural information processing systems. 2018.</p>
</div>
<div class="citation" id="m2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>M2013<span class="fn-bracket">]</span></span>
<p>Mikolov, Tomas, et al. “Distributed representations of words and phrases and their compositionality.” Advances in neural information processing systems. 2013.</p>
</div>
<div class="citation" id="nd2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ND2017<span class="fn-bracket">]</span></span>
<p>Nickel, Maximillian, and Douwe Kiela. “Poincaré embeddings for learning hierarchical representations.” Advances in neural information processing systems. 2017.</p>
</div>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="12_real_world_applications__emg_sign_classification_in_spd_manifold.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Hand gesture classification with EMG data using Riemannian metrics</p>
      </div>
    </a>
    <a class="right-next"
       href="14_real_world_applications__hand_poses_analysis_in_kendall_shape_space.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classifying hands poses with Kendall shape spaces</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Parameters-and-Initialization">Parameters and Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Loss-function.">Loss function.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Riemannian-optimization.">Riemannian optimization.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Capturing-the-graph-structure">Capturing the graph structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Numerically-optimizing-the-loss-function">Numerically optimizing the loss function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Plotting-results">Plotting results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#References">References</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/notebooks/13_real_world_applications__graph_embedding_and_clustering_in_hyperbolic_space.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2022-2023, Geomstats, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.2.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>